


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os


#Load dataset

data = pd.read_csv("../Dataset/bank_data_C.csv")
data.head()


data.describe(include = 'all')


data.info()


data.dtypes


#Creating a folder for visualization

output_dir = os.path.join(os.path.dirname(os.getcwd()), 'visualization')
os.makedirs(output_dir, exist_ok= True)





data.head(5)


#Checking for missing value

data.isnull().sum()


#Convert CustomerDOB and transaction date to datetime

data["CustomerDOB"] = pd.to_datetime(data["CustomerDOB"])
data["TransactionDate"] = pd.to_datetime(data["TransactionDate"], format = '%d/%m/%y')


#Checking for unique value
data["TransactionDate"].unique()


#Calculating the age of every customer by subtracting the transaction date from DOB
#We first create a new column for age

def calculate_age(data):
    data['Age'] = data["TransactionDate"].dt.year - data["CustomerDOB"].dt.year
    return data


data = calculate_age(data)
data.head()


#Observe and correct Customers negative age
data[data["Age"] < 0]["CustomerDOB"]


#Define a function to correct a negative age by adjusting the date of the year

def adjust_year(date):
    if date.year>2016:
        date = date.replace(year= date.year - 100)
    return date


data["CustomerDOB"] = data["CustomerDOB"].apply(adjust_year)


data = calculate_age(data)


data.head()


#To observe age distribution 
plt.figure(figsize=(8,6))
sns.set_palette("viridis")
sns.histplot(data['Age'], bins = 10, kde = False)
plt.xlabel('Age')
plt.ylabel('Frequency')
plt.title('Age distribution')
plt.show()


#examine the wrong entry
data[data["Age"] > 100]["CustomerDOB"].unique()


#Removing the outliers as a result of wrong entries
#Define function to fix outliers in age

def replace_age_outliers(data):
    DOB_threshold = 1900
    age_outliers = data[data["CustomerDOB"].dt.year < DOB_threshold].index

    mean_DOB = data[~data.index.isin(age_outliers)]["CustomerDOB"].mean()

    data.loc[age_outliers, "CustomerDOB"] = mean_DOB

    return data
    


data = replace_age_outliers(data)
data = calculate_age(data)


#To observe age distribution 
plt.figure(figsize=(8,6))
sns.histplot(data['Age'], bins = 10, kde = False)
plt.xlabel('Age')
plt.ylabel('Frequency')
plt.title('Age distribution')
plt.show()


#To observe Gender column

data["CustGender"].value_counts()


#Replace T in gender with M
data["CustGender"] = data["CustGender"].replace('T', 'M')


data["CustGender"].value_counts()


#To observe location column
data["CustLocation"].value_counts()


#To observe Account balance column
data["CustAccountBalance"].sort_values(ascending = True)


#observe transaction amount

data[data["TransactionAmount (INR)"]== 0].value_counts().sum()


#Drop all the rows with zero transactions

data.drop(data[data["TransactionAmount (INR)"] == 0].index.tolist(), axis = 0, inplace = True)


data[data["TransactionAmount (INR)"]== 0].value_counts().sum()


data.head()





#Checking for customer unique ID
data["CustomerID"].nunique()


data.shape


#plot a distribution for data across the unique transaction date
#based on the graph we only have 3 months worth of data

plt.figure(figsize=(8,6))
sns.histplot(data["TransactionDate"], bins = 3, kde = False)
plt.xlabel("Transaction Date")
plt.ylabel("Frequency")
plt.title("Transaction date distribution")
plt.show()


#Checking the distribution for Gender with pie chart

plt.figure(figsize=(8,8))
gender_count = data["CustGender"].value_counts()
plt.pie(gender_count, labels = gender_count.index, autopct= '%1.1f%%', startangle = 180)
plt.title("Pie chart of gender")
plt.show()





data.head(5)





#To understand how frequent a customer transact 
#To obtain a maximum day 
day = data["TransactionDate"].max()


day


recency = data.groupby(['CustomerID']).agg({"TransactionDate": lambda x: ((day - x.max()).days) +1})


recency.head()





#Calculating a transaction ID for every customer

frequency = data.drop_duplicates(subset = "TransactionID").groupby(["CustomerID"])[["TransactionID"]].count()


frequency.head(5)





#To get the total sum of all the transaction amount made by every customer

monetary = data.groupby("CustomerID")[["TransactionAmount (INR)"]].sum()


monetary.head(5)





#Concatenate Every individual table created to create overall RFM table
RFM_Table = pd.concat([recency, frequency, monetary], axis = 1)


RFM_Table.head()


#Rename column headings 
RFM_Table = RFM_Table.rename(columns = {"TransactionDate": "Recency", "TransactionID": "Frequency", "TransactionAmount (INR)": "Monetary"})
RFM_Table.head()





fig, axes = plt.subplots(1,3, figsize= (15,5))

columns = ["Recency", "Frequency", "Monetary"]
for i, col in enumerate(columns):
    axes[i].hist(RFM_Table[col], bins= 10, color = 'skyblue', edgecolor = 'black')
    axes[i].set_title(col)
    axes[i].set_xlabel("Days" if col == "Recency" else "count" if col == "Frequency" else "INR")
    axes[i].set_ylabel(col)

plt.tight_layout()
plt.show()
    


plt.figure(figsize=(8,6))
plt.hist(RFM_Table['Monetary'], bins = np.logspace(0,5,20), color = 'skyblue', edgecolor = 'black')
plt.title("Monetary value")
plt.xlabel('monetary value (log scale)')
plt.ylabel('frequency (log scale)')
plt.xscale('log')
plt.yscale('log')
plt.show()


RFM_Table.corr()





RFM_Table.head()


#Calculate the quartile for each column
quantile = RFM_Table[["Recency", "Frequency", "Monetary"]].quantile(q = [0.25, 0.5, 0.75]).to_dict() 


quantile


RFM_Table["Frequency"].value_counts()


#Creating a custom system for frequency

def assign_R_score(x, feature):
    if x <= quantile[feature][0.25]:
        return 4
    elif x <= quantile[feature][0.5]:
        return 3
    elif x <= quantile[feature][0.75]:
        return 3
    else:
        return 1

def assign_M_score(x, feature):
    if x <= quantile[feature][0.25]:
        return 1
    elif x <= quantile[feature][0.5]:
        return 2
    elif x <= quantile[feature][0.75]:
        return 3
    else:
        return 4


def custom_frequency_score(x):
    if x <=3:
        return x
    else:
        return 4


RFM_Table["R_score"] = RFM_Table["Recency"].apply(lambda x: assign_R_score(x, "Recency"))

RFM_Table["F_score"] =  RFM_Table["Frequency"].apply(custom_frequency_score)

RFM_Table["M_score"] = RFM_Table["Monetary"].apply(lambda x: assign_M_score(x, "Monetary"))


RFM_Table


#Creating a total score that will be a combination of all 3 scores

RFM_Table["RFM_Score"] = RFM_Table[["R_score", "F_score", "M_score"]].sum(axis=1)


RFM_Table.head(5)


#Creating RFM Group to understand the segment

RFM_Table["RFM_Group"] = RFM_Table["R_score"].astype(str) + RFM_Table["F_score"].astype(str) + RFM_Table["M_score"].astype(str)


RFM_Table.head()





#Visualize the distribution along the RFM_Score

plt.figure(figsize = (15, 5))
sns.countplot(x = RFM_Table["RFM_Score"])





def assign_segments(x):
    if x <= 5:
        return "low"
    elif x <= 9:
        return "medium"
    else:
        return "high"


RFM_Table["segments"] = RFM_Table["RFM_Score"].apply(lambda x: assign_segments(x))


RFM_Table.head()


#Visualize the distribution along the segments

plt.figure(figsize = (10, 5))
sns.countplot(x = RFM_Table["segments"])





if "weighted Score" in RFM_Table.columns:
    RFM_Table.drop("weighted Score", axis=1, inplace=True)

RFM_Table["weighted score"] = (RFM_Table['R_score'] * 2) + (RFM_Table['F_score'] * 1) + (RFM_Table['M_score'] * 1)


RFM_Table.head()


#Visualize weighted_score

plt.figure(figsize = (10, 5))
sns.countplot(x = RFM_Table["weighted score"])


#Creating RFM Weighted segment

RFM_Table["weighted segment"] = RFM_Table["weighted score"].apply(lambda x: assign_segments(x))


RFM_Table.head()


#Visualize weighted_segment

plt.figure(figsize = (10, 5))
sns.countplot(x = RFM_Table["weighted segment"])








import sklearn
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import yellowbrick
from yellowbrick.cluster import KElbowVisualizer
from sklearn.decomposition import PCA





RFM_data = RFM_Table.drop(["RFM_Group", "segments", "weighted score", "weighted segment"], axis=1)


RFM_data.head()





scaler = StandardScaler()


scaled_data = scaler.fit_transform(RFM_data)


scaled_data





model = KMeans(random_state = 1)





#finding the optimum number of cluster
plot_model = KElbowVisualizer(model, k = (2,10), metric = "distortion", timing = False)
plot_model.fit(scaled_data)


#Using calinski - harabasz metric to get the optimum number of cluster

plot_model_2 = KElbowVisualizer(model, k = (2,10), metric = "calinski_harabasz", timing = False)
plot_model_2.fit(scaled_data)





final_model = KMeans(random_state = 1, n_clusters = 3)
final_model.fit(scaled_data)


cluster_assignment = final_model.labels_
cluster_assignment


RFM_data["Cluster"] = cluster_assignment


RFM_data


#Visualizing cluster to see how data are spread

plt.figure(figsize=(10,10))
sns.scatterplot(data = RFM_data, x = RFM_data["Recency"], y = RFM_data["Monetary"], hue = RFM_data["Cluster"], palette = "viridis")



#Creating a 3D visualization
fig = plt.figure(figsize=(10,10))
ax = fig.add_subplot(111, projection = "3d")

color = ['b', 'g', 'r']
for cluster, color in zip(RFM_data["Cluster"].unique(), color):
    cluster_data = RFM_data[RFM_data["Cluster"] == cluster]
    ax.scatter(cluster_data["Recency"], cluster_data["Frequency"], cluster_data["Monetary"], c = color, s = 50, marker = 'o', label = f"Cluster {cluster}")

ax.set_xlabel("Recency")
ax.set_ylabel("Frequency")
ax.set_zlabel("Monetary")

ax.legend()
plt.title("3D plot of RFM clusters")
plt.show()


#Checking the count of every customer in each cluster

sns.countplot(x = RFM_data["Cluster"], hue=RFM_data["Cluster"], palette = "viridis", legend = False)


#Draw out a descriptive statistics for every individual customer

for cluster in RFM_data["Cluster"].unique():
    print(f"cluster: {cluster}")
    print(RFM_data[RFM_data["Cluster"] == cluster].describe())


#Draw a boxplot for every cluster

cluster_0 = RFM_data[RFM_data["Cluster"] == 0]
cluster_1 = RFM_data[RFM_data["Cluster"] == 1]
cluster_2 = RFM_data[RFM_data["Cluster"] == 2]


plt.figure(figsize=(10,6))
sns.boxplot(data = cluster_0[["R_score", "F_score", "M_score"]])
plt.title(f"cluster_0")
plt.ylabel("values")
plt.xlabel("features")
plt.show()

plt.figure(figsize=(10,6))
sns.boxplot(data = cluster_1[["R_score", "F_score", "M_score"]])
plt.title(f"cluster_1")
plt.ylabel("values")
plt.xlabel("features")
plt.show()

plt.figure(figsize=(10,6))
sns.boxplot(data = cluster_2[["R_score", "F_score", "M_score"]])
plt.title(f"cluster_2")
plt.ylabel("values")
plt.xlabel("features")
plt.show()















