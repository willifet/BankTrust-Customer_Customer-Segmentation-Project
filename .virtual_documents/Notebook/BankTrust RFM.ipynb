


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns


#Load dataset

data = pd.read_csv("../Dataset/bank_data_C.csv")
data.head()


data.describe(include = 'all')


data.info()


data.dtypes





data.head(5)


#Checking for missing value

data.isnull().sum()


#Convert CustomerDOB and transaction date to datetime

data["CustomerDOB"] = pd.to_datetime(data["CustomerDOB"])
data["TransactionDate"] = pd.to_datetime(data["TransactionDate"], format = '%d/%m/%y')


#Checking for unique value
data["TransactionDate"].unique()


#Calculating the age of every customer by subtracting the transaction date from DOB
#We first create a new column for age

def calculate_age(data):
    data['Age'] = data["TransactionDate"].dt.year - data["CustomerDOB"].dt.year
    return data


data = calculate_age(data)
data.head()


#Observe and correct Customers negative age
data[data["Age"] < 0]["CustomerDOB"]


#Define a function to correct a negative age by adjusting the date of the year

def adjust_year(date):
    if date.year>2016:
        date = date.replace(year= date.year - 100)
    return date


data["CustomerDOB"] = data["CustomerDOB"].apply(adjust_year)


data = calculate_age(data)


data.head()


#To observe age distribution 
plt.figure(figsize=(8,6))
sns.histplot(data['Age'], bins = 10, kde = False)
plt.xlabel('Age')
plt.ylabel('Frequency')
plt.title('Age distribution')
plt.show()


#examine the wrong entry
data[data["Age"] > 100]["CustomerDOB"].unique()


#Removing the outliers as a result of wrong entries
#Define function to fix outliers in age

def replace_age_outliers(data):
    DOB_threshold = 1900
    age_outliers = data[data["CustomerDOB"].dt.year < DOB_threshold].index

    mean_DOB = data[~data.index.isin(age_outliers)]["CustomerDOB"].mean()

    data.loc[age_outliers, "CustomerDOB"] = mean_DOB

    return data
    


data = replace_age_outliers(data)
data = calculate_age(data)


#To observe age distribution 
plt.figure(figsize=(8,6))
sns.histplot(data['Age'], bins = 10, kde = False)
plt.xlabel('Age')
plt.ylabel('Frequency')
plt.title('Age distribution')
plt.show()


#To observe Gender column

data["CustGender"].value_counts()


#Replace T in gender with M
data["CustGender"] = data["CustGender"].replace('T', 'M')


data["CustGender"].value_counts()


#To observe location column
data["CustLocation"].value_counts()


#To observe Account balance column
data["CustAccountBalance"].sort_values(ascending = True)


#observe transaction amount

data[data["TransactionAmount (INR)"]== 0].value_counts().sum()


#Drop all the rows with zero transactions

data.drop(data[data["TransactionAmount (INR)"] == 0].index.tolist(), axis = 0, inplace = True)


data[data["TransactionAmount (INR)"]== 0].value_counts().sum()


data.head()





#Checking for customer unique ID
data["CustomerID"].nunique()


data.shape


#plot a distribution for data across the unique transaction date
#based on the graph we only have 3 months worth of data

plt.figure(figsize=(8,6))
sns.histplot(data["TransactionDate"], bins = 3, kde = False)
plt.xlabel("Transaction Date")
plt.ylabel("Frequency")
plt.title("Transaction date distribution")
plt.show()


#Checking the distribution for Gender with pie chart

plt.figure(figsize=(8,8))
gender_count = data["CustGender"].value_counts()
plt.pie(gender_count, labels = gender_count.index, autopct= '%1.1f%%', startangle = 180)
plt.title("Pie chart of gender")
plt.show()





data.head(5)





#To understand how frequent a customer transact 
#To obtain a maximum day 
day = data["TransactionDate"].max()


day


recency = data.groupby(['CustomerID']).agg({"TransactionDate": lambda x: ((day - x.max()).days) +1})


recency.head()





#Calculating a transaction ID for every customer

frequency = data.drop_duplicates(subset = "TransactionID").groupby(["CustomerID"])[["TransactionID"]].count()


frequency.head(5)





#To get the total sum of all the transaction amount made by every customer

monetary = data.groupby("CustomerID")[["TransactionAmount (INR)"]].sum()


monetary.head(5)





#Concatenate Every individual table created to create overall RFM table
RFM_Table = pd.concat([recency, frequency, monetary], axis = 1)


RFM_Table.head()


#Rename column headings 
RFM_Table = RFM_Table.rename(columns = {"TransactionDate": "Recency", "TransactionID": "Frequency", "TransactionAmount (INR)": "Monetary"})
RFM_Table.head()






